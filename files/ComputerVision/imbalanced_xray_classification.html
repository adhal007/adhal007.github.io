<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-label Classification of X-Rays using DenseNet</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
        }
        img {
            max-width: 100%;
            height: auto;
            margin: 20px 0;
        }
        .note {
            background-color: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 15px;
            margin: 20px 0;
        }
        ul {
            margin-left: 20px;
        }
        .clipboard-copy {
            position: absolute;
            right: 10px;
            top: 10px;
            padding: 4px 8px;
            background: #fff;
            border: 1px solid #ddd;
            border-radius: 3px;
            cursor: pointer;
        }
    </style>
    <script type="module" src="https://unpkg.com/@github/clipboard-copy-element@latest"></script>
</head>
<body>
    <h1>Multi-label Classification of X-Rays</h1>

    <h2>1. Required Imports and Setup</h2>
    <pre>
import keras
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras import backend as K 
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

import src.utils.xraypp as xraypp
import src.utils.plotter as pltter
import src.utils.batchgenerator as dg
import src.utils.models as dl_models
    </pre>

    <h2>0.1. Initialize the xray preprocessor object</h2>
    <pre>
HOME_DIR_2D = "./data/nih/images-small/"
DATA_DIR_2D = HOME_DIR_2D
train_df = pd.read_csv("./data/nih/train-small.csv")
valid_df = pd.read_csv("./data/nih/valid-small.csv")
test_df = pd.read_csv("./data/nih/test.csv")
labels = ['Cardiomegaly', 
          'Emphysema', 
          'Effusion', 
          'Hernia', 
          'Infiltration', 
          'Mass', 
          'Nodule', 
          'Atelectasis',
          'Pneumothorax',
          'Pleural_Thickening', 
          'Pneumonia', 
          'Fibrosis', 
          'Edema', 
          'Consolidation']
xray_pp_obj = xraypp.XrayPP(
                 train_df=train_df,
                 valid_df=valid_df,
                 test_df=test_df,
                 img_dir=DATA_DIR_2D,
                 target_w=320,
                 target_h=320,
                 labels=labels,
                 )
    </pre>

    <p>Output from XrayPP initialization:</p>
    <pre>
06/04//2024 01:21:1712389902 PM - INFO - XrayPP: Initializing the Medical Image Preprocessor Class
06/04//2024 01:21:1712389902 PM - INFO - ComputeStats: Initializing the Compute Stats Class
06/04//2024 01:21:1712389902 PM - INFO - XrayPP: Initializing the X-ray image preprocessing class
06/04//2024 01:21:1712389902 PM - INFO - XrayPP: Initializing the X-ray image preprocessing class
06/04//2024 01:21:1712389902 PM - INFO - XrayPP: Image Directory: data/nih/images-small
06/04//2024 01:21:1712389902 PM - INFO - XrayPP: Image Directory: data/nih/images-small
    </pre>

    <pre>
dg_xray = xray_pp_obj.get_generator(batch_size=32, num_channels=2)
    </pre>

    <p>Generator initialization output:</p>
    <pre>
06/04//2024 01:21:1712389903 PM - INFO - XrayPP: Initializing the Data Generator For Training, Testing and Validation generators
Found 1000 validated image filenames.
Found 1000 validated image filenames.
Found 200 validated image filenames.
Found 420 validated image filenames.
    </pre>

    <pre>
xray_pp_obj.update_kwargs()
    </pre>
    <h2>1.0. Applying DenseNet Model using models and compute stats modules to imbalanced Chest X-Ray Datasets</h2>
    <pre>
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from keras.preprocessing.image import ImageDataGenerator
from keras.applications.densenet import DenseNet121
from keras.layers import Dense, GlobalAveragePooling2D
from keras.models import Model
from keras import backend as K

from keras.models import load_model

import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
    </pre>

    <h2>1.1. Get contributions and frequencies of positive, negative classes using training data</h2>
    <pre>
model_obj = dl_models.DLModels(
    model_2d_dir='./models/nih/densenet.hdf5', 
    model_3d_dir='./models/pretrained_model.h5', 
    pre_trained_wts='./models/nih/pretrained_model.h5'
)
labels = xray_pp_obj.labels
freq_pos, freq_neg = model_obj.cs.compute_class_freqs(train_generator.labels)
pos_neg_dict = model_obj.cs.calc_pos_neg_weights(freq_pos=freq_pos, freq_neg=freq_neg)
    </pre>

    <p>Model initialization output:</p>
    <pre>
06/04//2024 01:21:1712389910 PM - INFO - DLModels: Initializing the Deep Learning Model Class
06/04//2024 01:21:1712389910 PM - INFO - ComputeStats: Initializing the Compute Stats Class
06/04//2024 01:21:1712389910 PM - INFO - ComputeStats: Initializing the Compute Stats Class
    </pre>

    <h3>Class Distribution Analysis Before Balancing</h3>
    <pre>
# Create DataFrame for positive values
pos_data = pd.DataFrame({"Class": labels, "Label": "Positive", "Value": freq_pos})

# Create DataFrame for negative values
neg_data = pd.DataFrame([{"Class": labels[l], "Label": "Negative", "Value": v} 
                        for l, v in enumerate(freq_neg)])

# Concatenate positive and negative data
data = pd.concat([pos_data, neg_data], ignore_index=True)

# Plot data
plt.xticks(rotation=90)
f = sns.barplot(x="Class", y="Value", hue="Label", data=data)
f.set_title('Class distribution Before Balancing')
    </pre>

    <img src="imbalanced_xray_classification_files/imbalanced_xray_classification_12_1.png" 
         alt="Class distribution before balancing">

    <h3>Class Distribution Analysis After Balancing</h3>
    <pre>
# Create DataFrame for positive contributions
pos_data = pd.DataFrame({
    "Class": labels, 
    "Label": "Positive", 
    "Value": pos_neg_dict['pos_contribution']
})

# Create DataFrame for negative contributions
neg_data = pd.DataFrame([{
    "Class": labels[l], 
    "Label": "Negative", 
    "Value": v
} for l, v in enumerate(pos_neg_dict['neg_contribution'])])

# Concatenate positive and negative contributions
data = pd.concat([pos_data, neg_data], ignore_index=True)

# Plot data
plt.xticks(rotation=90)
g = sns.barplot(x="Class", y="Value", hue="Label", data=data)
g.set_title('Class distribution After Balancing')
    </pre>

    <img src="imbalanced_xray_classification_files/imbalanced_xray_classification_13_1.png" 
         alt="Class distribution after balancing">

    <div class="note">
        <p>The plots above demonstrate how we address class imbalance in the dataset. The first plot shows the original distribution of positive and negative cases for each condition, while the second plot shows the balanced distribution after applying our weighting strategy.</p>
    </div>
    <h2>2. Evaluation and Interpretation</h2>
    
    <h2>2.1. Model Prediction Performance</h2>
    <pre>
import random
random.seed(a=None, version=2)
auc_rocs = model_obj.cs.get_roc_curve(labels, predicted_vals, test_generator)
    </pre>

    <p>ROC Curves for Different Pathologies:</p>
    <img src="imbalanced_xray_classification_files/imbalanced_xray_classification_22_0.png" alt="ROC Curves">

    <h2>2.2. Model Interpretation</h2>
    <div class="note">
        <p>One of the challenges of using deep learning in medicine is that the complex architecture used for neural networks makes them much harder to interpret compared to traditional machine learning models. Class Activation Maps (CAM) help us understand where the model is "looking" when classifying an image.</p>
    </div>

    <p>Key points about Class Activation Maps:</p>
    <ul>
        <li>They help visualize important regions in the image for predicting pathological conditions</li>
        <li>We use GradCAM's technique to produce heatmaps highlighting important regions</li>
        <li>While not providing full explanation, they are useful for "debugging" our model</li>
        <li>They help experts validate that predictions focus on relevant image regions</li>
    </ul>

    <h2>3. Generating GradCAM Visualizations</h2>
    <p>We generate GradCAM visualizations for the top 4 performing classes:</p>
    <pre>
# only show the labels with top 4 AUC
labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:4]
model_obj.cs.compute_gradcam(model_2d, 
                           img='00008270_015.png', 
                           image_dir=DATA_DIR_2D, 
                           df=train_df, 
                           labels=labels, 
                           selected_labels=labels_to_show, 
                           W=320, H=320)
    </pre>

    <p>Output from GradCAM generation:</p>
    <pre>
1/1 [==============================] - 1s 766ms/step
Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema
    </pre>

    <img src="imbalanced_xray_classification_files/imbalanced_xray_classification_24_1.png" alt="GradCAM Visualization">

    <h2>4. Additional Example</h2>
    <p>Let's look at another example with a different X-ray image:</p>
    <pre>
img_ex = '00011355_002.png'
model_obj.cs.compute_gradcam(model_2d, 
                           img=img_ex, 
                           image_dir=DATA_DIR_2D, 
                           df=train_df, 
                           labels=labels, 
                           selected_labels=labels_to_show, 
                           W=320, H=320)
    </pre>

    <img src="imbalanced_xray_classification_files/imbalanced_xray_classification_25_1.png" alt="Second GradCAM Visualization">

    <h2>Conclusion</h2>
    <p>The GradCAM visualizations demonstrate that our model is focusing on anatomically relevant regions for each pathological condition. This provides confidence that the model is learning meaningful features rather than spurious correlations in the data.</p>

</body>
</html>